"use strict";

/*
TODO:
  resource: https://medium.com/@muhammedcan.erbudak/ray-tracing-from-scratch-brdfs-object-lights-path-tracing-d68f7b6ad22c
  implement bounces and just focus for now on if it hits the light source ever. Illuminate with the radiance value of the light 
  (then implement lighting features like (attenuation)) -think I already covered this
*/

const UPDATE_INTERVAL = 500;
//surface geometry of cornell box
let date = new Date();
var camera = new Float32Array([
  278, 273, -800, date.getMilliseconds(),
]);
const floorQuad = [
  552.8, 0.0, 0.0, 0.0,
  0.0, 0.0, 0.0, 0.0,
  0.0, 0.0, 559.2, 0.0,
  549.6, 0.0, 559.2, 0.0,
];
// const lightPos = [
//   343.0, 548.8, 227.0, 0.0,
// ];
const ceilingQuad = [
  556.0, 548.8, 0.0, 0.0,
  556.0, 548.8, 559.2, 0.0,
  0.0, 548.8, 559.2, 0.0,
  0.0, 548.8, 0.0, 0.0,
];
const backWallQuad = [
  549.6, 0.0, 559.2, 0.0,
  0.0, 0.0, 559.2, 0.0,
  0.0, 548.8, 559.2, 0.0,
  556.0, 548.8, 559.2, 0.0,
];
const rightWallQuad = [ //green
  0.0, 0.0, 559.2, 0.0,
  0.0, 0.0, 0.0, 0.0,
  0.0, 548.8, 0.0, 0.0,
  0.0, 548.8, 559.2, 0.0,
];
const leftWallQuad = [ //red
  552.8, 0.0, 0.0,  0.0,
  549.6, 0.0, 559.2, 0.0,
  556.0, 548.8, 559.2, 0.0,
  556.0, 548.8, 0.0, 0.0,
];

async function main() {
  const adapter = await navigator.gpu?.requestAdapter();
  const hasBGRA8unormStorage = adapter.features.has('bgra8unorm-storage');
  const device = await adapter?.requestDevice({
    requiredFeatures: hasBGRA8unormStorage
      ? ['bgra8unorm-storage']
      : [],
  });
  if (!device) {
    fail('need a browser that supports WebGPU');
    return;
  }

  // Get a WebGPU context from the canvas and configure it
  const canvas = document.querySelector('canvas');
  const context = canvas.getContext('webgpu');
  const presentationFormat = hasBGRA8unormStorage
    ? navigator.gpu.getPreferredCanvasFormat()
    : 'rgba8unorm';
  context.configure({
    device,
    format: presentationFormat,
    usage: GPUTextureUsage.TEXTURE_BINDING |
          GPUTextureUsage.STORAGE_BINDING,
  });

  const module = device.createShaderModule({
    label: 'circles in storage texture',
    code: `
    @group(0) @binding(0) var tex: texture_storage_2d<${presentationFormat}, write>;
@group(0) @binding(1) var<storage, read> vertColorBuffer: array<vec4f>; //vec4f for now, could have it stay vec4 and just jump over 2 to get the color data
@group(0) @binding(2) var<uniform> camera: vec4f;

const lightPosition = vec3f(300.0, 538.8, 227.0); // Position of the light
const lightRadius = f32(50.0); // Radius of the light sphere

//const camera = vec3f(278.0, 273.0, -800.0);
const epsilon: f32 = 0.000000115;
const M_PI: f32 = 3.1415926535897932384626433832795;

// from https://stackoverflow.com/questions/4200224/random-noise-functions-for-glsl
  // A single iteration of Bob Jenkins' One-At-A-Time hashing algorithm.
  fn hash(x: u32) -> u32 {
    var x_var = x;
    x_var = x_var + (x_var << 10u);
    x_var = x_var ^ (x_var >> 6u);
    x_var = x_var + (x_var << 3u);
    x_var = x_var ^ (x_var >> 11u);
    x_var = x_var + (x_var << 15u);
    return x_var;
  } 
  
  // Compound versions of the hashing algorithm I whipped together.
  fn hash1(v: vec2<u32>) -> u32 {
    return hash(v.x ^ hash(v.y));
  } 
  
  fn hash2(v: vec3<u32>) -> u32 {
    return hash(v.x ^ (hash(v.y) ^ hash(v.z)));
  } 
  
  fn hash3(v: vec4<u32>) -> u32 {
    return hash(v.x ^ (hash(v.y) ^ (hash(v.z) ^ hash(v.w))));
  } 
  
  // Construct a float with half-open range [0:1] using low 23 bits.
  // All zeroes yields 0.0, all ones yields the next smallest representable value below 1.0.
  fn floatConstruct(m: u32) -> f32 {
    var m_var = m;
    let ieeeMantissa: u32 = 8388607u; // binary32 mantissa bitmask
    let ieeeOne: u32 = 1065353216u; // 1.0 in IEEE binary32
    m_var = m_var & (ieeeMantissa); // Keep only mantissa bits (fractional part)
    m_var = m_var | (ieeeOne); // Add fractional part to 1.0
    let f: f32 = bitcast<f32>(m_var); // Range [1:2]
    return f - 1.0; // Range [0:1]
  } 
  
  // Pseudo-random value in half-open range [0:1].
  fn rand(x: f32) -> f32 {
    return floatConstruct(hash(bitcast<u32>(x)));
  } 
  
  fn rand1(v: vec2<f32>) -> f32 {
    return floatConstruct(hash1(vec2u(bitcast<u32>(v.x), bitcast<u32>(v.y))));
  } 
  
  fn rand2(v: vec3<f32>) -> f32 {
    return floatConstruct(hash2(  vec3u( bitcast<u32>(v.x), bitcast<u32>(v.y), bitcast<u32>(v.z)   )));
  } 
  
  fn rand3(v: vec4<f32>) -> f32 {
    return floatConstruct(hash3(   vec4u( bitcast<u32>(v.x), bitcast<u32>(v.y), bitcast<u32>(v.z), bitcast<u32>(v.w)   )));
  } 
  
  // end rand

struct newRay {
    rayO: vec3f,
    rayD: vec3f,
};

// create triangle
fn createTri(i: i32) -> mat3x3<f32> {
    return mat3x3<f32>(vertColorBuffer[i].xyz, vertColorBuffer[i + 1].xyz, vertColorBuffer[i + 2].xyz);
}

// sphere intersection function
fn intersectSphere(rayOrigin: vec3f, rayDir: vec3f, sphereCenter: vec3f, sphereRadius: f32) -> f32 {
    let oc = vec3f(rayOrigin - sphereCenter);
    let a = f32(dot(rayDir, rayDir));
    let b = f32(2.0 * dot(oc, rayDir));
    let c = f32(dot(oc, oc) - sphereRadius * sphereRadius);
    let discriminant = f32(b * b - 4.0 * a * c);

    if (discriminant < 0.0) {
        return -1.0; // No intersection
    } else {
        return f32((-b - sqrt(discriminant)) / (2.0 * a)); // Closest intersection
    }
}

// tri intersection formula
fn rayIntersect(rayO: vec3<f32>, rayD: vec3<f32>, tri: mat3x3<f32>) -> vec4<f32> {
    let edge1: vec3<f32> = tri[1] - tri[0];
    let edge2: vec3<f32> = tri[2] - tri[0];
    let ray_cross_e2: vec3<f32> = cross(rayD, edge2);
    let det: f32 = dot(edge1, ray_cross_e2);
    if (det > -epsilon && det < epsilon) {
        return vec4<f32>(0.0);
    }
    let inv_det: f32 = 1. / det;
    let s: vec3<f32> = rayO - tri[0];
    let u: f32 = inv_det * dot(s, ray_cross_e2);
    if (u < 0. || u > 1.) {
        return vec4<f32>(0.0);
    }
    let s_cross_e1: vec3<f32> = cross(s, edge1);
    let v: f32 = inv_det * dot(rayD, s_cross_e1);
    if (v < 0. || u + v > 1.) {
        return vec4<f32>(0.0);
    }
    let t: f32 = inv_det * dot(edge2, s_cross_e1);
    if (t > epsilon) {
        let intersection_point: vec3<f32> = rayO + rayD * t;
        return vec4<f32>(intersection_point, 1.);
    } else { 
        return vec4<f32>(0.0);
    }
}

// Lambertian reflectance
fn lambertianReflectance(normal: vec3<f32>, lightDir: vec3<f32>) -> f32 {
    return max(dot(normalize(normal), normalize(lightDir)), 0.1);
}

// Compute radiance
fn computeRadiance(intersectionPoint: vec3<f32>, normal: vec3<f32>, lightPos: vec3<f32>, lightIntensity: f32) -> vec3<f32> {
    let lightDir = lightPos - intersectionPoint;
    let distance = length(lightDir) * 0.01;
    let radiance = lightIntensity / (distance * distance) * lambertianReflectance(normal, lightDir);
    
    // Logarithmic adjustment
    let adjustedRadiance = 1.0 * log(1.08 + radiance);
    return vec3<f32>(adjustedRadiance);
}

fn randHemisphereRay(i: i32, pos: vec2f) -> vec3<f32> {
	let j: f32 = f32(i);
	let theta: f32 = rand2(vec3<f32>(camera.w + j * 46.340346, pos.x + j * 93.4567970, pos.y + j * 12.30347)) * 2. * M_PI;
	let phi: f32 = rand2(vec3<f32>(pos.y + j * 23.3424567903, pos.x + j * 9.8346795, camera.w + j * 23.20679673)) * M_PI / 2.;
	return normalize(vec3<f32>(sin(phi) * cos(theta), cos(phi), sin(theta) * sin(phi)));
} 

fn squaredDistance(p1: vec3<f32>, p2: vec3<f32>) -> f32 {
	let diff: vec3<f32> = p1 - p2;
	return dot(diff, diff);
} 



@compute @workgroup_size(1) fn cs(
    @builtin(global_invocation_id) id : vec3u
)  {
    let size = textureDimensions(tex);
    let pos = id.xy;

    // Create ray for pixel
    var rayDir = normalize(vec3<f32>(
        (f32(pos.x) / f32(size.x)) * 2.0 - 1.0,
        1.0 - (f32(pos.y) / f32(size.y)) * 2.0,
        2.0
    ));
    var rayOrigin = camera.xyz; 
    var tempColor = vec4<f32>(0.0, 0.0, 0.0, 1.0);
    var hitSphere = intersectSphere(rayOrigin, rayDir, lightPosition, lightRadius);

    // Initialize variables for storing the closest intersection and its normal
    var closestIntersection = vec4<f32>(9000.0);
    var closestNormal = vec3<f32>(0.0);
    var foundIntersection = false;
    var index = 0;
    let numTris = i32(arrayLength(&vertColorBuffer)/4);

    // Check for intersections with triangles
    for (var g = 0; g < 20; g++) {
      for (var i = 0; i < numTris; i++) {
          let currTri = createTri(i * 4);
          let intersectionResult = rayIntersect(rayOrigin + vec3f(vec2f(rand(camera.w + f32(g))), 0.0), rayDir, currTri);
          if (intersectionResult.w != 0.0) { // found ray
              // all of this works for lambertian shading, commenting out color for now for bounce testing
              if (squaredDistance(intersectionResult.xyz, rayOrigin) < squaredDistance(closestIntersection.xyz, rayOrigin)) {
                //tempColor += vertColorBuffer[i * 4 + 3];
                closestIntersection = intersectionResult;
                closestNormal = normalize(cross(currTri[1] - currTri[0], currTri[2] - currTri[0]));
                foundIntersection = true;
                index = i;
                // end lambert
              }
              
          }
      }

      //try bounce to check for light
      if (foundIntersection) {
        tempColor += vertColorBuffer[index * 4 + 3];
        // make new ray
        var newHemiRay = randHemisphereRay(index + g, rayDir.xy);
        //checking if it's in the right hemisphere
        if (dot(newHemiRay, closestNormal) < 0.0) {
          newHemiRay = -newHemiRay; // if not fix it
        }

        if (intersectSphere(closestIntersection.xyz, newHemiRay, lightPosition, lightRadius) != -1.0) {
          //tempColor += vec4f(1.0);
          // basic shadow
          for (var j = 0; j < numTris; j++) {
            let shadowTri = createTri(j * 4);
            let shadowResult = rayIntersect(closestIntersection.xyz + newHemiRay*vec3(0.0001), newHemiRay, shadowTri);
            if (shadowResult.w != 0.0) { // if it hits geometry it's in shadow
              if (squaredDistance(closestIntersection.xyz, shadowResult.xyz) < squaredDistance(lightPosition, shadowResult.xyz)) {
                tempColor -= vertColorBuffer[index * 4 + 3];
                break;
              }
            }
          }
        } else {
          tempColor -= vertColorBuffer[index * 4 + 3];
          
        }
      }
    }

    // Calculate radiance at the closest intersection point
    if (foundIntersection) {
        let radiance = computeRadiance(closestIntersection.xyz, closestNormal, lightPosition, 10.0); // light intensity is really high right now
        tempColor = vec4<f32>(radiance, 1.0) * tempColor;
    }

    // Write color to texture
    if (hitSphere == -1.0) {
        if (foundIntersection) {
            textureStore(tex, pos, tempColor);
            //textureStore(tex, pos, vec4f(500.0/camera.w));
            //textureStore(tex, pos, vec4f(rand3(vec4f(camera.w, f32(pos.x), f32(pos.y), 1.0))));
        } else {
            let color = vec4<f32>(
                f32(pos.x) / f32(size.x),
                f32(pos.y) / f32(size.y),
                0.0,
                1.0
            );
            textureStore(tex, pos, color);
        }
    } else {
        textureStore(tex, pos, vec4<f32>(1.0, 1.0, 1.0, 1.0));
    }
}

    
    `,
  });

  const pipeline = device.createComputePipeline({
    label: 'pathTracer Pipeline',
    layout: 'auto',
    compute: {
      module,
      //entryPoint: "cs",
    },
  });

  //ssbo
  const vertColorBufferData = new Float32Array([
    // floor
    552.8, 0.0, 0.0, 0.0,
    0.0, 0.0, 0.0, 0.0,
    0.0, 0.0, 559.2, 0.0,
    // color 1
    0.9, 0.9, 0.9, 1.0,

    552.8, 0.0, 0.0, 0.0,
    0.0, 0.0, 559.2, 0.0,
    549.6, 0.0, 559.2, 0.0,
    // color 2
    0.9, 0.9, 0.9, 1.0,

    // ceiling
    556.0, 548.8, 0.0, 0.0,
    556.0, 548.8, 559.2, 0.0,
    0.0, 548.8, 559.2, 0.0,
    // color 3
    0.9, 0.9, 0.9, 1.0,

    556.0, 548.8, 0.0, 0.0,
    0.0, 548.8, 559.2, 0.0,
    0.0, 548.8, 0.0, 0.0,
    // color 4
    0.9, 0.9, 0.9, 1.0,

    // back wall
    549.6, 0.0, 559.2, 0.0,
    0.0, 0.0, 559.2, 0.0,
    0.0, 548.8, 559.2, 0.0,
    // color 5
    0.9, 0.9, 0.9, 1.0,

    549.6, 0.0, 559.2, 0.0,
    0.0, 548.8, 559.2, 0.0,
    556.0, 548.8, 559.2, 0.0,
    // color 6
    0.9, 0.9, 0.9, 1.0, 

    // // right wall
    0.0, 0.0, 559.2, 0.0,
    0.0, 0.0, 0.0, 0.0,
    0.0, 548.8, 0.0, 0.0,
    // color 7
    0.1, 0.9, 0.1, 1.0,
    
    0.0, 0.0, 559.2, 0.0,
    0.0, 548.8, 0.0, 0.0,
    0.0, 548.8, 559.2, 0.0,
    // color 8
    0.1, 0.9, 0.1, 1.0,

    // // left wall
    552.8, 0.0, 0.0,  0.0,
    549.6, 0.0, 559.2, 0.0,
    556.0, 548.8, 559.2, 0.0,
    // color 9
    0.9, 0.1, 0.1, 1.0,

    552.8, 0.0, 0.0,  0.0,
    556.0, 548.8, 559.2, 0.0,
    556.0, 548.8, 0.0, 0.0,
    // color 10
    0.9, 0.1, 0.1, 1.0,

    //box
    // bluish 0.05, 0.1, 0.7, 1.0,
    
    130.0, 165.0,  65.0, 0.0, 
    82.0, 165.0, 225.0, 0.0,
    240.0, 165.0, 272.0, 0.0,
    0.05, 0.1, 0.7, 1.0,

    130.0, 165.0,  65.0, 0.0, 
    240.0, 165.0, 272.0, 0.0,
    290.0, 165.0, 114.0, 0.0,
    0.05, 0.1, 0.7, 1.0,

    290.0,   0.0, 114.0, 0.0,
    290.0, 165.0, 114.0, 0.0,
    240.0, 165.0, 272.0, 0.0,
    0.05, 0.1, 0.7, 1.0,

    290.0,   0.0, 114.0, 0.0,
    240.0, 165.0, 272.0, 0.0,
    240.0,   0.0, 272.0, 0.0,
    0.05, 0.1, 0.7, 1.0,

    130.0,   0.0,  65.0, 0.0,
    130.0, 165.0,  65.0, 0.0,
    290.0, 165.0, 114.0, 0.0,
    0.05, 0.1, 0.7, 1.0,

    130.0,   0.0,  65.0, 0.0,
    290.0, 165.0, 114.0, 0.0,
    290.0,   0.0, 114.0, 0.0,
    0.05, 0.1, 0.7, 1.0,

    82.0,   0.0, 225.0, 0.0,
    82.0, 165.0, 225.0, 0.0,
    130.0, 165.0,  65.0, 0.0,
    0.05, 0.1, 0.7, 1.0,

    82.0,   0.0, 225.0, 0.0,
    130.0,   0.0,  65.0, 0.0,
    130.0, 165.0,  65.0, 0.0,
    0.05, 0.1, 0.7, 1.0,

    240.0,   0.0, 272.0, 0.0,
    240.0, 165.0, 272.0, 0.0,
    82.0, 165.0, 225.0, 0.0,
    0.05, 0.1, 0.7, 1.0,

    240.0,   0.0, 272.0, 0.0,
    82.0, 165.0, 225.0, 0.0,
    82.0,  0.0, 225.0, 0.0,
    0.05, 0.1, 0.7, 1.0,
    
  ]);
  const vertColorBuffer = device.createBuffer({
    label: 'vertex and vertex color Buffer',
    size: vertColorBufferData.byteLength,
    usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
  });

  device.queue.writeBuffer(vertColorBuffer, 0, vertColorBufferData);

  const cameraBuffer = device.createBuffer({
    label: "camera and time buffer",
    size: camera.byteLength,
    usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
  });
  device.queue.writeBuffer(cameraBuffer, 0, camera);

  function render() {
    const texture = context.getCurrentTexture();

    const bindGroup = device.createBindGroup({
      layout: pipeline.getBindGroupLayout(0),
      entries: [
        { binding: 0, resource: texture.createView() },
        {binding: 1, resource: { buffer: vertColorBuffer}},
        {binding: 2, resource: {buffer: cameraBuffer}},
        // vertex + color buffer
        // camera + time buffer
      ],
    });
  
    const encoder = device.createCommandEncoder({ label: 'our encoder' });
    const pass = encoder.beginComputePass();
    pass.setPipeline(pipeline);
    pass.setBindGroup(0, bindGroup);
    date = new Date();
    camera[3] = date.getMilliseconds();
    device.queue.writeBuffer(cameraBuffer, 0, camera); // not sure if I have to recall here
    pass.dispatchWorkgroups(texture.width, texture.height); // could be optimized
    pass.end();

    const commandBuffer = encoder.finish();
    device.queue.submit([commandBuffer]);
  }

  const observer = new ResizeObserver(entries => {
    for (const entry of entries) {
      const canvas = entry.target;
      const width = entry.contentBoxSize[0].inlineSize;
      const height = entry.contentBoxSize[0].blockSize;
      canvas.width = Math.max(1, Math.min(width, device.limits.maxTextureDimension2D));
      canvas.height = Math.max(1, Math.min(height, device.limits.maxTextureDimension2D));
      // re-render
      render();
    }
  });
  observer.observe(canvas);

  //setInterval(render, UPDATE_INTERVAL);

}

function fail(msg) {
  // eslint-disable-next-line no-alert
  alert(msg);
}

main();
  